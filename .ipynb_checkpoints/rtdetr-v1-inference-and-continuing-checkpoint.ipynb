{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6022989,"sourceType":"datasetVersion","datasetId":3446572}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install ultralytics\n!pip install -U ipywidgets\n!pip install wandb","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-11T14:47:06.608416Z","iopub.execute_input":"2024-03-11T14:47:06.609256Z","iopub.status.idle":"2024-03-11T14:47:49.542385Z","shell.execute_reply.started":"2024-03-11T14:47:06.609221Z","shell.execute_reply":"2024-03-11T14:47:49.541205Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import wandb","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:47:49.544118Z","iopub.execute_input":"2024-03-11T14:47:49.544384Z","iopub.status.idle":"2024-03-11T14:47:50.740229Z","shell.execute_reply.started":"2024-03-11T14:47:49.544360Z","shell.execute_reply":"2024-03-11T14:47:50.739484Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nmy_secret = user_secrets.get_secret(\"wandb_api_key\") \n\nwandb.login(key=my_secret)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:47:50.741243Z","iopub.execute_input":"2024-03-11T14:47:50.741493Z","iopub.status.idle":"2024-03-11T14:47:53.238669Z","shell.execute_reply.started":"2024-03-11T14:47:50.741470Z","shell.execute_reply":"2024-03-11T14:47:53.237669Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import os\n\ntrain_labels = \"/kaggle/working/datasets/tables/lables/train\"\nval_labels = \"/kaggle/working/datasets/tables/lables/val\"\ntest_labels = \"/kaggle/working/datasets/tables/lables/test\"\n\nos.makedirs(train_labels, exist_ok=True)\nos.makedirs(test_labels, exist_ok=True)\nos.makedirs(val_labels, exist_ok=True)\n\n\ntrain_dir = \"/kaggle/working/datasets/tables/images/train\"\nval_dir = \"/kaggle/working/datasets/tables/images/val\"\ntest_dir = \"/kaggle/working/datasets/tables/images/test\"\n\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\nos.makedirs(val_dir, exist_ok=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:47:53.240681Z","iopub.execute_input":"2024-03-11T14:47:53.241108Z","iopub.status.idle":"2024-03-11T14:47:53.248942Z","shell.execute_reply.started":"2024-03-11T14:47:53.241082Z","shell.execute_reply":"2024-03-11T14:47:53.247769Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\n\ninput_train_labels = \"/kaggle/working/tables/lables/train\"\ninput_val_labels = \"/kaggle/working/tables/lables/val\"\ninput_test_labels = \"/kaggle/working/tables/lables/test\"\n\nos.makedirs(input_train_labels, exist_ok=True)\nos.makedirs(input_test_labels, exist_ok=True)\nos.makedirs(input_val_labels, exist_ok=True)\n\n\ninput_train_dir = \"/kaggle/working/tables/images/train\"\ninput_val_dir = \"/kaggle/working/tables/images/val\"\ninput_test_dir = \"/kaggle/working/tables/images/test\"\n\nos.makedirs(input_train_dir, exist_ok=True)\nos.makedirs(input_test_dir, exist_ok=True)\nos.makedirs(input_val_dir, exist_ok=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:47:53.250303Z","iopub.execute_input":"2024-03-11T14:47:53.250736Z","iopub.status.idle":"2024-03-11T14:47:53.271537Z","shell.execute_reply.started":"2024-03-11T14:47:53.250704Z","shell.execute_reply":"2024-03-11T14:47:53.270728Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"import os\nimport xml.etree.ElementTree as ET\n\ndirectory = \"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\"\n\ncount1 = 0\ncount2 = 0\n\nfor filename in tqdm(os.listdir(directory)[1:10000]):\n    if filename.endswith(\".xml\"):\n        filepath = os.path.join(directory, filename)\n        with open(filepath, \"r\") as in_file:\n            tree = ET.parse(in_file)\n            root = tree.getroot()\n\n            for obj in root.iter('object'):\n                cls = obj.find('name').text\n                if cls == \"table\":\n                    count1 += 1\n                else:\n                    count2 += 1\n                    print(obj.find('name').text)\n\nprint(f\"Count of 'table' in :\", count1)\nprint(f\"Count of other classes in:\", count2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:40:17.716381Z","iopub.execute_input":"2024-03-10T21:40:17.716997Z","iopub.status.idle":"2024-03-10T21:40:23.743996Z","shell.execute_reply.started":"2024-03-10T21:40:17.716965Z","shell.execute_reply":"2024-03-10T21:40:23.743073Z"}}},{"cell_type":"code","source":"xml_files = [f for f in os.listdir(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\") if f.endswith('.xml')]\n\nlen(xml_files)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:47:53.272605Z","iopub.execute_input":"2024-03-11T14:47:53.272883Z","iopub.status.idle":"2024-03-11T14:47:54.102904Z","shell.execute_reply.started":"2024-03-11T14:47:53.272859Z","shell.execute_reply":"2024-03-11T14:47:54.102032Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"57125"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\ninput_dir = \"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\"\n\nrandom.shuffle(xml_files)\n\ntrain = xml_files[:40000]\nval = xml_files[40000:50000]\ntest = xml_files[50000:57000]","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:47:57.476359Z","iopub.execute_input":"2024-03-11T14:47:57.477205Z","iopub.status.idle":"2024-03-11T14:47:57.533967Z","shell.execute_reply.started":"2024-03-11T14:47:57.477171Z","shell.execute_reply":"2024-03-11T14:47:57.533075Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm  \nimport shutil\n\nfor xml in tqdm(test):\n    image_name = xml.split('.')[0] \n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\", xml), input_test_labels)\n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Images_Test\", image_name + '.jpg'), input_test_dir)\n\nfor xml in tqdm(val):\n    image_name = xml.split('.')[0] \n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\", xml), input_val_labels)\n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Images_Test\", image_name + '.jpg'), input_val_dir)\n\nfor xml in tqdm(train):\n    image_name = xml.split('.')[0] \n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\", xml), input_train_labels)\n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Images_Test\", image_name + '.jpg'), input_train_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:48:00.732069Z","iopub.execute_input":"2024-03-11T14:48:00.732766Z","iopub.status.idle":"2024-03-11T15:06:56.816901Z","shell.execute_reply.started":"2024-03-11T14:48:00.732731Z","shell.execute_reply":"2024-03-11T15:06:56.815970Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7000/7000 [02:26<00:00, 47.80it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [03:15<00:00, 51.17it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40000/40000 [13:14<00:00, 50.37it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"import os\nimport shutil\nimport xml.etree.ElementTree as ET\nfrom tqdm import tqdm  \n\ndef convert_coordinates(image_width, image_height, xmin, ymin, xmax, ymax):\n    # Normalize coordinates\n    center_x = (xmin + xmax) / (2 * image_width)\n    center_y = (ymin + ymax) / (2 * image_height)\n    width = (xmax - xmin) / image_width\n    height = (ymax - ymin) / image_height\n    return center_x, center_y, width, height\n\ndef convert_to_yolo(xml_file, output_dir, out):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    \n\n    image_name = root.find('filename').text.split('.')[0]  # Remove extension\n    shutil.copy(os.path.join(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Images_Test\", image_name + '.jpg' ), out)\n\n\n    image_width = float(root.find('size/width').text)\n    image_height = float(root.find('size/height').text)\n\n    yolo_annotations = []\n\n    for obj in root.findall('object'):\n        class_name = obj.find('name').text\n        class_index = 0  # Assuming only one class \"table\" as per the provided example\n\n        xmin = float(obj.find('bndbox/xmin').text)\n        ymin = float(obj.find('bndbox/ymin').text)\n        xmax = float(obj.find('bndbox/xmax').text)\n        ymax = float(obj.find('bndbox/ymax').text)\n\n        center_x, center_y, width, height = convert_coordinates(image_width, image_height, xmin, ymin, xmax, ymax)\n        yolo_annotations.append(f\"{class_index} {center_x} {center_y} {width} {height}\")\n\n    output_file = os.path.join(output_dir, f\"{image_name}.txt\")\n    with open(output_file, 'w') as f:\n        f.write('\\n'.join(yolo_annotations))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:12:03.244369Z","iopub.execute_input":"2024-03-10T17:12:03.244869Z","iopub.status.idle":"2024-03-10T17:12:03.261739Z","shell.execute_reply.started":"2024-03-10T17:12:03.244842Z","shell.execute_reply":"2024-03-10T17:12:03.260897Z"}}},{"cell_type":"markdown","source":"xml_files = [f for f in os.listdir(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\") if f.endswith('.xml')]\nlen(xml_files)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:12:03.262707Z","iopub.execute_input":"2024-03-10T17:12:03.262977Z","iopub.status.idle":"2024-03-10T17:12:03.983037Z","shell.execute_reply.started":"2024-03-10T17:12:03.262954Z","shell.execute_reply":"2024-03-10T17:12:03.982152Z"}}},{"cell_type":"markdown","source":"import random\n\ninput_dir = \"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test\"\n\nrandom.shuffle(xml_files)\n\ntrain = xml_files[:5000]\nval = xml_files[5000:7000]\ntest = xml_files[7000:9000]\n\n\n\ntotal_files = len(train)\nwith tqdm(total=total_files) as pbar:\n    for xml_file in train:\n        convert_to_yolo(os.path.join(input_dir, xml_file), train_labels,train_dir)\n        pbar.update(1)\n        \n        \ntotal_files = len(val)\nwith tqdm(total=total_files) as pbar:\n    for xml_file in val:\n        convert_to_yolo(os.path.join(input_dir, xml_file), val_labels,val_dir)\n        pbar.update(1)\n        \n        \ntotal_files = len(test)\nwith tqdm(total=total_files) as pbar:\n    for xml_file in test:\n        convert_to_yolo(os.path.join(input_dir, xml_file), test_labels,test_dir)\n        pbar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:12:03.984349Z","iopub.execute_input":"2024-03-10T17:12:03.984715Z","iopub.status.idle":"2024-03-10T17:13:39.746773Z","shell.execute_reply.started":"2024-03-10T17:12:03.98468Z","shell.execute_reply":"2024-03-10T17:13:39.745753Z"}}},{"cell_type":"markdown","source":"print(\"Number of files in train images directory:\", len(os.listdir(train_dir)))\nprint(\"Number of files in test labels directory:\", len(os.listdir(test_labels)))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:13:39.74811Z","iopub.execute_input":"2024-03-10T17:13:39.748396Z","iopub.status.idle":"2024-03-10T17:13:39.758791Z","shell.execute_reply.started":"2024-03-10T17:13:39.74837Z","shell.execute_reply":"2024-03-10T17:13:39.757876Z"}}},{"cell_type":"markdown","source":"import yaml\n\n# YAML data as a string\nyaml_data = \"\"\"\npath: /kaggle/working/datasets/tables\ntrain: \n  - images/train\nval: \n  - images/val\ntest:\n  - images/test\nnames:\n  0: table\n\ndownload: |\n  import xml.etree.ElementTree as ET\n  import os\n  from tqdm import tqdm\n  from ultralytics.utils.downloads import download\n  from pathlib import Path\n\n  def convert_label(path, lb_path, image_id):\n      def convert_box(size, box):\n          dw, dh = 1. / size[0], 1. / size[1]\n          x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]\n          return x * dw, y * dh, w * dw, h * dh\n\n      in_file = open(\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test/{image_id}.xml\")\n      out_file = open(lb_path, 'w')\n      tree = ET.parse(in_file)\n      root = tree.getroot()\n      size = root.find('size')\n      w = int(size.find('width').text)\n      h = int(size.find('height').text)\n\n      names = list(data['names'].values())  # names list\n      for obj in root.iter('object'):\n          cls = obj.find('name').text\n          if cls in names and int(obj.find('difficult').text) != 1:\n              xmlbox = obj.find('bndbox')\n              bb = convert_box((w, h), [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')])\n              out_file.write(\" \".join(str(a) for a in ('0', *bb)) + '\\\\n')\n\n  # Download\n  dir = Path(data['path'])  # dataset root dir\n\n  # Convert\n  path = dir / 'images'\n  for image_set in 'train', 'val', 'test':\n      imgs_path = dir / 'images' / f'{image_set}'\n      lbs_path = dir / 'labels' / f'{image_set}'\n      imgs_path.mkdir(exist_ok=True, parents=True)\n      lbs_path.mkdir(exist_ok=True, parents=True)\n\n      image_ids = []\n      for filename in os.listdir(f\"/kaggle/working/tables/images/{image_set}\"):\n          if filename.endswith(\".jpg\"):\n              image_ids.append(os.path.splitext(filename)[0])\n\n      for image_id in tqdm(image_ids, desc=f'{image_set}'):\n          f = f'/kaggle/working/tables/images/{image_set}/{image_id}.jpg'  # old img path\n          lb_path = (lbs_path / f.name).with_suffix('.txt')  # new label path\n          f.rename(imgs_path / f.name)  # move image\n          convert_label(path, lb_path, image_id)  # convert labels to YOLO format\n\"\"\"\n\n# Save YAML data to a file\nfile_path = '/kaggle/working/datasets/tables/data.yaml'\n\nwith open(file_path, 'w') as yaml_file:\n    yaml_file.write(yaml_data)\n\nprint(f\"YAML file created at {file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T20:50:00.90472Z","iopub.execute_input":"2024-03-10T20:50:00.905113Z","iopub.status.idle":"2024-03-10T20:50:00.915472Z","shell.execute_reply.started":"2024-03-10T20:50:00.90508Z","shell.execute_reply":"2024-03-10T20:50:00.914393Z"}}},{"cell_type":"code","source":"import yaml\n\n# YAML data as a string\nyaml_data = \"\"\"\npath: /kaggle/working/datasets/tables\ntrain: \n  - images/train\nval: \n  - images/val\ntest:\n  - images/test\nnames:\n  0: table\n  1: table rotated\n  \n  \"\"\"\n\n\n# Save YAML data to a file\nfile_path = '/kaggle/working/datasets/tables/data.yaml'\n\nwith open(file_path, 'w') as yaml_file:\n    yaml_file.write(yaml_data)\n\nprint(f\"YAML file created at {file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:07:05.849120Z","iopub.execute_input":"2024-03-11T15:07:05.849773Z","iopub.status.idle":"2024-03-11T15:07:05.856357Z","shell.execute_reply.started":"2024-03-11T15:07:05.849737Z","shell.execute_reply":"2024-03-11T15:07:05.855402Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"YAML file created at /kaggle/working/datasets/tables/data.yaml\n","output_type":"stream"}]},{"cell_type":"code","source":"import yaml\nfrom pathlib import Path\n\n\nwith open(file_path, 'r') as file:\n    data = yaml.load(file, Loader=yaml.FullLoader)\n\n\ndir = Path(data['path'])  # dataset root dir\n\npath = dir / 'images'\n\npath","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:07:09.024043Z","iopub.execute_input":"2024-03-11T15:07:09.024650Z","iopub.status.idle":"2024-03-11T15:07:09.033798Z","shell.execute_reply.started":"2024-03-11T15:07:09.024622Z","shell.execute_reply":"2024-03-11T15:07:09.032924Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/working/datasets/tables/images')"},"metadata":{}}]},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport os\nfrom tqdm import tqdm\nfrom pathlib import Path\n\n\n\ndef convert_label(path, lb_path, image_id):\n    def convert_box(size, box):\n        dw, dh = 1. / size[0], 1. / size[1]\n        x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]\n        return x * dw, y * dh, w * dw, h * dh\n\n    in_file = open(f\"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Annotations_Test/{image_id}.xml\")\n    out_file = open(lb_path, 'w')\n    tree = ET.parse(in_file)\n    root = tree.getroot()\n    size = root.find('size')\n    w = int(size.find('width').text)\n    h = int(size.find('height').text)\n\n    names = list(data['names'].values())  # names list\n    for obj in root.iter('object'): \n        cls = obj.find('name').text\n        if cls in names and int(obj.find('difficult').text) != 1:\n            xmlbox = obj.find('bndbox')\n            bb = convert_box((w, h), [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')])\n            cls_id = names.index(cls)\n            out_file.write(\" \".join(str(a) for a in (cls_id, *bb)) + '\\n')\n\ndir = Path(data['path'])  # dataset root dir\n\npath = dir / 'images'\nfor image_set in 'train', 'val', 'test':\n    imgs_path = dir / 'images' / f'{image_set}'\n    lbs_path = dir / 'labels' / f'{image_set}'\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    image_ids = []\n    for filename in os.listdir(f\"/kaggle/working/tables/images/{image_set}\"):\n        if filename.endswith(\".jpg\"):\n            image_ids.append(os.path.splitext(filename)[0])\n\n    for image_id in tqdm(image_ids, desc=f'{image_set}'):\n        f = f'/kaggle/working/tables/images/{image_set}/{image_id}.jpg'  # old img path\n        f_name = os.path.basename(f)\n        lb_path = (lbs_path / f_name).with_suffix('.txt')  # new label path\n        os.rename(f, imgs_path / f_name)  # move image\n        convert_label(path, lb_path, image_id)  # convert labels to YOLO format\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:07:11.510284Z","iopub.execute_input":"2024-03-11T15:07:11.510648Z","iopub.status.idle":"2024-03-11T15:08:43.363807Z","shell.execute_reply.started":"2024-03-11T15:07:11.510619Z","shell.execute_reply":"2024-03-11T15:08:43.362834Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40000/40000 [00:56<00:00, 713.79it/s]\nval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:17<00:00, 565.17it/s]\ntest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7000/7000 [00:17<00:00, 390.82it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from ultralytics import RTDETR\n\nmodel = RTDETR('rtdetr-l.pt')\n\nmodel.info()\n\nresults = model.train(data='/kaggle/working/datasets/tables/data.yaml', epochs= 10, batch=32, save_period = 2, device=[0,1])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!wget \"https://file.io/Ovhj4V3iyAzQ\" -O best.pt","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:49:51.544818Z","iopub.execute_input":"2024-03-11T15:49:51.545197Z","iopub.status.idle":"2024-03-11T15:49:52.729542Z","shell.execute_reply.started":"2024-03-11T15:49:51.545164Z","shell.execute_reply":"2024-03-11T15:49:52.728305Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"--2024-03-11 15:49:52--  https://file.io/Ovhj4V3iyAzQ\nResolving file.io (file.io)... 45.55.107.24\nConnecting to file.io (file.io)|45.55.107.24|:443... connected.\nHTTP request sent, awaiting response... 404 Not Found\n2024-03-11 15:49:52 ERROR 404: Not Found.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import RTDETR\n\nmodel = RTDETR('/kaggle/working/best.pt')\n\nmodel.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:26:39.193254Z","iopub.execute_input":"2024-03-11T15:26:39.193663Z","iopub.status.idle":"2024-03-11T15:26:51.353808Z","shell.execute_reply.started":"2024-03-11T15:26:39.193630Z","shell.execute_reply":"2024-03-11T15:26:51.352814Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"rt-detr-l summary: 677 layers, 32810186 parameters, 0 gradients, 108.0 GFLOPs\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(677, 32810186, 0, 107.9962624)"},"metadata":{}}]},{"cell_type":"code","source":"metrics = model.val(data='/kaggle/working/datasets/tables/data.yaml',split='test')  \nmetrics.box.map    \nmetrics.box.map75 \nmetrics.box.maps   ","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:29:20.641118Z","iopub.execute_input":"2024-03-11T15:29:20.641793Z","iopub.status.idle":"2024-03-11T15:33:56.265711Z","shell.execute_reply.started":"2024-03-11T15:29:20.641763Z","shell.execute_reply":"2024-03-11T15:33:56.264472Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.26 üöÄ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\nrt-detr-l summary: 498 layers, 31987850 parameters, 0 gradients, 103.4 GFLOPs\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 14.9MB/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/tables/labels/test... 7000 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7000/7000 [00:09<00:00, 718.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/tables/labels/test.cache\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 438/438 [04:13<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       7000       8359      0.999      0.998      0.995      0.993\n                 table       7000       8303      0.999      0.997      0.995      0.995\n         table rotated       7000         56      0.998          1      0.995      0.992\nSpeed: 0.2ms preprocess, 32.6ms inference, 0.0ms loss, 0.3ms postprocess per image\nResults saved to \u001b[1mruns/detect/val\u001b[0m\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([    0.99477,     0.99197])"},"metadata":{}}]},{"cell_type":"code","source":"metrics.box.map    \n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:33:56.268900Z","iopub.execute_input":"2024-03-11T15:33:56.269971Z","iopub.status.idle":"2024-03-11T15:33:56.276782Z","shell.execute_reply.started":"2024-03-11T15:33:56.269927Z","shell.execute_reply":"2024-03-11T15:33:56.275634Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.9933675999308857"},"metadata":{}}]},{"cell_type":"code","source":"metrics.box.all_ap \n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:34:20.200832Z","iopub.execute_input":"2024-03-11T15:34:20.201214Z","iopub.status.idle":"2024-03-11T15:34:20.207511Z","shell.execute_reply.started":"2024-03-11T15:34:20.201185Z","shell.execute_reply":"2024-03-11T15:34:20.206550Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([[     0.9949,      0.9949,      0.9949,     0.99487,     0.99487,     0.99484,     0.99484,      0.9948,     0.99465,      0.9941],\n       [      0.995,       0.995,       0.995,       0.995,       0.995,       0.995,       0.995,       0.995,       0.995,     0.96469]])"},"metadata":{}}]},{"cell_type":"code","source":"metrics.box.maps   ","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:33:56.292856Z","iopub.execute_input":"2024-03-11T15:33:56.293805Z","iopub.status.idle":"2024-03-11T15:33:56.302563Z","shell.execute_reply.started":"2024-03-11T15:33:56.293778Z","shell.execute_reply":"2024-03-11T15:33:56.301744Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([    0.99477,     0.99197])"},"metadata":{}}]},{"cell_type":"code","source":"!wget \"https://file.io/e8C20Nswi55L\" -O epoch8.pt","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:49:06.642743Z","iopub.execute_input":"2024-03-11T15:49:06.643609Z","iopub.status.idle":"2024-03-11T15:49:47.654483Z","shell.execute_reply.started":"2024-03-11T15:49:06.643566Z","shell.execute_reply":"2024-03-11T15:49:47.653497Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"--2024-03-11 15:49:07--  https://file.io/e8C20Nswi55L\nResolving file.io (file.io)... 45.55.107.24\nConnecting to file.io (file.io)|45.55.107.24|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [application/octet-stream]\nSaving to: 'epoch8.pt'\n\nepoch8.pt               [          <=>       ] 377.05M  10.0MB/s    in 40s     \n\n2024-03-11 15:49:47 (9.53 MB/s) - 'epoch8.pt' saved [395366676]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import RTDETR\n\nmodel = RTDETR('/kaggle/working/epoch8.pt')\nmodel.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T15:57:55.800247Z","iopub.execute_input":"2024-03-11T15:57:55.800982Z","iopub.status.idle":"2024-03-11T15:57:57.922078Z","shell.execute_reply.started":"2024-03-11T15:57:55.800951Z","shell.execute_reply":"2024-03-11T15:57:57.921192Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"rt-detr-l summary: 677 layers, 32810186 parameters, 0 gradients, 108.0 GFLOPs\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(677, 32810186, 0, 107.9962624)"},"metadata":{}}]},{"cell_type":"code","source":"results = model.train(data='/kaggle/working/datasets/tables/data.yaml', resume ='true')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T16:11:54.485349Z","iopub.execute_input":"2024-03-11T16:11:54.486176Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.1.26 üöÄ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/epoch8.pt, data=/kaggle/working/datasets/tables/data.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=2, cache=False, device=[0, 1], workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 43257 /root/.config/Ultralytics/DDP/_temp_5pg09wou132660456432512.py\nUltralytics YOLOv8.1.26 üöÄ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n","output_type":"stream"},{"name":"stderr","text":"2024-03-11 16:12:03.194387: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-11 16:12:03.194460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-11 16:12:03.196499: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: sreesankar711. Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.16.4 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.16.3\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240311_161205-j668irkl\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run train\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/sreesankar711/YOLOv8\nwandb: üöÄ View run at https://wandb.ai/sreesankar711/YOLOv8/runs/j668irkl\n","output_type":"stream"},{"name":"stdout","text":"WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='l'.\nTransferred 941/941 items from pretrained weights\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/tables/labels/train.cache... 40000 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40000/40000 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC2817860_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC3039408_6.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC3415468_13.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC3576625_10.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC3686582_7.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC4948083_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC6014042_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/working/datasets/tables/images/train/PMC6147433_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/tables/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 10 epochs...\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/1250 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      10/10      12.8G    0.03351    0.08404    0.03556         18        640:  36%|‚ñà‚ñà‚ñà‚ñã      | 454/1250 [08:27<14:41,  1.11s/it]","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n\ni = 1\n\nfor file in os.listdir(test_dir):\n    results= model(os.path.join(test_dir,file))\n    \n    for result in results:     \n        boxes = result.boxes \n        masks = result.masks\n        #Masks object for segmentation masks outputs\n        keypoints = result.keypoints # Keypoints object for pose outputs\n        probs = result.probs #Probs object for classification outputs\n        result.save(filename= f'result{i}.jpg')\n        i = i + 1\n        \n        \n    if i > 1000:\n            break\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Load the image\nfor i in range(1,1000):\n    image_path = f\"/kaggle/working/result{i}.jpg\"\n    image = Image.open(image_path)\n\n    plt.imshow(image)\n    plt.axis('off')  \n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}